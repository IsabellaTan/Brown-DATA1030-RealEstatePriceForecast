{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99d9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "#  Load small dataset\n",
    "X_small = pd.read_csv('../data/X_small.csv')\n",
    "y_small = pd.read_csv('../data/y_small.csv').squeeze()   # convert to Series\n",
    "\n",
    "\n",
    "#  Identify common vs rare states\n",
    "state_counts = X_small['state'].value_counts()\n",
    "common_states = state_counts[state_counts >= 2].index\n",
    "rare_states = state_counts[state_counts < 2].index\n",
    "\n",
    "# masks\n",
    "mask_common = X_small['state'].isin(common_states)\n",
    "mask_rare   = X_small['state'].isin(rare_states)\n",
    "\n",
    "X_small_common = X_small[mask_common]\n",
    "y_small_common = y_small[mask_common]\n",
    "\n",
    "X_small_rare = X_small[mask_rare]\n",
    "y_small_rare = y_small[mask_rare]\n",
    "\n",
    "# Split common states into Train / Test\n",
    "X_train_c, X_test, y_train_c, y_test = train_test_split(\n",
    "    X_small_common,\n",
    "    y_small_common,\n",
    "    train_size=0.7,\n",
    "    stratify=X_small_common['state'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Add rare states ONLY to train\n",
    "X_train = pd.concat([X_train_c, X_small_rare], axis=0).reset_index(drop=True)\n",
    "y_train = pd.concat([y_train_c, y_small_rare], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Reset test set index\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59524a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\data1030\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\data1030\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\data1030\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\data1030\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\data1030\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\data1030\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\data1030\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\data1030\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\data1030\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing Pipeline\n",
    "\n",
    "# preprocess with pipeline and columntransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "# collect the various features\n",
    "cat_ftrs = ['status','city','state']\n",
    "num_ftrs = ['bed','bath','acre_lot','house_size']\n",
    "zip_ftr = 'zip_code'\n",
    "broker_ftr = 'brokered_by'\n",
    "street_ftr = 'street'\n",
    "sold_ftr = 'prev_sold_date'\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "class BinaryTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # NA → 0；非 NA → 1\n",
    "        return np.where(pd.isna(X), 0, 1).reshape(-1,1)\n",
    "\n",
    "class ZipCodeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.iloc[:, 0]\n",
    "        zip_str = X.astype(str)\n",
    "        zip_str = zip_str.str.split('.').str[0]\n",
    "        # 去掉非数字字符（例如 \"#####\", \"nan\", etc.）\n",
    "        zip_str = zip_str.apply(lambda s: ''.join(ch for ch in s if ch.isdigit()))\n",
    "        # 空字符串 → 视为缺失\n",
    "        zip_str = zip_str.replace('', np.nan)\n",
    "        # 缺失 ZIP → 用 \"00000\" 填充\n",
    "        zip_str = zip_str.fillna(\"00000\")\n",
    "        # ⭐ 最重要：统一补足为 5 位 ZIP（不足前补零）\n",
    "        zip_str = zip_str.str.zfill(5)\n",
    "        return zip_str.values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "class ZipLatLonTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, zip_lookup_path):\n",
    "        self.zip_lookup_path = zip_lookup_path\n",
    "    def fit(self, X, y=None):\n",
    "        # 读取 ZIP → LAT, LON 映射表\n",
    "        df = pd.read_csv(self.zip_lookup_path)\n",
    "        # 标准化 ZIP：补齐 5 位（string）\n",
    "        df['zip'] = df['zip'].astype(str).str.zfill(5)\n",
    "        # 保存映射表\n",
    "        self.lookup = df.set_index('zip')[['lat', 'lon']]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # 如果 X 是 DataFrame，取第一列\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.iloc[:, 0]\n",
    "        # 转字符串\n",
    "        zip_str = X.astype(str).str.split('.').str[0]\n",
    "        # 去掉非数字\n",
    "        zip_str = zip_str.apply(lambda s: ''.join(ch for ch in s if ch.isdigit()))\n",
    "        # 空字符串填 \"00000\"\n",
    "        zip_str = zip_str.replace('', np.nan).fillna(\"00000\")\n",
    "        # 全部补齐为 5 位\n",
    "        zip_str = zip_str.str.zfill(5)\n",
    "        # 根据 ZIP 查 lat/lon\n",
    "        lat = zip_str.map(self.lookup['lat'])\n",
    "        lon = zip_str.map(self.lookup['lon'])\n",
    "        # 返回两列 LAT, LON\n",
    "        out = np.column_stack([lat.values, lon.values])\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class PrevSoldDateTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.iloc[:, 0]     # 只有一列\n",
    "        else:\n",
    "            X = pd.Series(X)\n",
    "\n",
    "        dates = pd.to_datetime(X, errors='coerce')\n",
    "        years = (datetime.now() - dates).dt.days / 365\n",
    "        years = years.fillna(-1)\n",
    "\n",
    "        return years.values.reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "# one-hot encoder and imputer\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=True,handle_unknown='ignore'))])\n",
    "# standard scaler and imputer\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=10, random_state=42)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "tree_numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=10, random_state=42))])\n",
    "\n",
    "broker_pipe = Pipeline(steps=[\n",
    "    ('binary', BinaryTransformer())\n",
    "])\n",
    "street_pipe = Pipeline(steps=[\n",
    "    ('binary', BinaryTransformer())\n",
    "])\n",
    "zip_pipe = Pipeline(steps=[\n",
    "    ('zip_transform', ZipCodeTransformer()),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "])\n",
    "\n",
    "zip_latlon_pipe = Pipeline([\n",
    "    ('zip_to_latlon', ZipLatLonTransformer(\"../data/zip_lat_lon.csv\")),  \n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "sold_pipe = Pipeline(steps=[\n",
    "    ('sold_transform', PrevSoldDateTransformer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "tree_sold_pipe = Pipeline(steps=[\n",
    "    ('sold_transform', PrevSoldDateTransformer())\n",
    "])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('broker', broker_pipe, broker_ftr),\n",
    "        ('street', street_pipe, street_ftr),\n",
    "        ('zip', zip_pipe, zip_ftr),\n",
    "        ('sold', sold_pipe, sold_ftr)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "\n",
    "tree_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', tree_numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('broker', broker_pipe, broker_ftr),\n",
    "        ('street', street_pipe, street_ftr),\n",
    "        ('zip', zip_latlon_pipe, zip_ftr),\n",
    "        ('sold', tree_sold_pipe, sold_ftr)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "\n",
    "xgb_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('broker', broker_pipe, broker_ftr),\n",
    "        ('street', street_pipe, street_ftr),\n",
    "        ('zip', zip_latlon_pipe, zip_ftr),\n",
    "        ('sold', tree_sold_pipe, sold_ftr)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# ---------------------------- Linear Preprocessor ----------------------------\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "# ---------------------------- Tree Preprocessor ----------------------------\n",
    "X_train_tree = tree_preprocessor.fit_transform(X_train)\n",
    "X_test_tree = tree_preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "# 避免 log10(0) 错误，加一个非常小的常数（安全做法）\n",
    "y_train_log = np.log10(y_train + 1e-6)\n",
    "y_test_log = np.log10(y_test + 1e-6)\n",
    "\n",
    "# ---------------------------- XGBoost Preprocessor ----------------------------\n",
    "X_valid, X_test_final, y_valid, y_test_final = train_test_split(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    test_size=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "# Fit preprocessor only on training data\n",
    "xgb_preprocessor.fit(X_train)\n",
    "# Transform train / valid / test\n",
    "X_train_xgb = xgb_preprocessor.transform(X_train)\n",
    "X_valid_xgb = xgb_preprocessor.transform(X_valid)\n",
    "X_test_xgb  = xgb_preprocessor.transform(X_test_final)\n",
    "\n",
    "y_valid_log_xgb = np.log10(y_valid + 1e-6)\n",
    "y_test_log_xgb  = np.log10(y_test_final + 1e-6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfab0b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0 | Best alpha = 10  | Test RMSE = 0.8989 | Test R² = -1.9672\n",
      "Seed 42 | Best alpha = 10  | Test RMSE = 0.8989 | Test R² = -1.9672\n",
      "Seed 141 | Best alpha = 10  | Test RMSE = 0.8989 | Test R² = -1.9672\n",
      "\n",
      "----------------- Summary ---------------\n",
      "\n",
      "Mean RMSE (log10 space): 0.8989\n",
      "Std RMSE (log10 space):  0.0000\n",
      "Mean R² (log10 space):   -1.9672\n",
      "Std R² (log10 space):    0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "alpha_values = [0.01, 0.1, 1, 10, 100]\n",
    "seeds = [0, 42, 141]\n",
    "\n",
    "rmse_list = []\n",
    "r2_list = []\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    # Shuffle KFold with different random_state\n",
    "    cv = KFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    ridge = Ridge()\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=ridge,\n",
    "        param_grid={'alpha': alpha_values},\n",
    "        cv=cv,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit on training data 用 log 之后的 y 来 fit\n",
    "    grid.fit(X_train_processed, y_train_log)\n",
    "\n",
    "    best_ridge = grid.best_estimator_\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred_log = best_ridge.predict(X_test_processed)\n",
    "\n",
    "    rmse_log = mean_squared_error(y_test_log, y_pred_log) ** 0.5\n",
    "    r2_log = r2_score(y_test_log, y_pred_log)\n",
    "\n",
    "    rmse_list.append(rmse_log)\n",
    "    r2_list.append(r2_log)\n",
    "\n",
    "    print(f\"Seed {seed} | Best alpha = {grid.best_params_['alpha']}  | Test RMSE = {rmse_log:.4f} | Test R² = {r2_log:.4f}\")\n",
    "\n",
    "print(\"\\n----------------- Summary ---------------\\n\")\n",
    "print(f\"Mean RMSE (log10 space): {np.mean(rmse_list):.4f}\")\n",
    "print(f\"Std RMSE (log10 space):  {np.std(rmse_list):.4f}\")\n",
    "print(f\"Mean R² (log10 space):   {np.mean(r2_list):.4f}\")\n",
    "print(f\"Std R² (log10 space):    {np.std(r2_list):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04b7e1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed 0 | Best Params: {'max_depth': 20, 'max_features': 0.3, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "Best CV RMSE: 0.35773514549268476\n",
      "Test RMSE = 0.3614 | Test R² = 0.5203\n",
      "\n",
      "Seed 42 | Best Params: {'max_depth': 30, 'max_features': 0.3, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "Best CV RMSE: 0.3545143746364025\n",
      "Test RMSE = 0.3583 | Test R² = 0.5287\n",
      "\n",
      "Seed 141 | Best Params: {'max_depth': 10, 'max_features': 0.3, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "Best CV RMSE: 0.35451722240720684\n",
      "Test RMSE = 0.3624 | Test R² = 0.5178\n",
      "\n",
      "----------------- Summary ---------------\n",
      "\n",
      "Mean RMSE (log10 space): 0.3607\n",
      "Std RMSE (log10 space):  0.0018\n",
      "Mean R²  (log10 space):  0.5223\n",
      "Std R²   (log10 space):   0.0046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# Parameter Grid\n",
    "# -------------------------\n",
    "param_grid = {\n",
    "    \"max_depth\": [5, 10, 20, 30],       # 树深度\n",
    "    \"min_samples_split\": [2, 10],        # 内部节点最小样本数\n",
    "    \"min_samples_leaf\": [1, 5,10],          # 叶节点最小样本数\n",
    "    \"max_features\": [\"sqrt\", 0.3]      # 特征选择方式\n",
    "}\n",
    "\n",
    "# 和 Ridge 一样，用多个 seed 作为不同的 set\n",
    "seeds = [0, 42, 141]\n",
    "\n",
    "rmse_list = []\n",
    "r2_list = []\n",
    "\n",
    "# -------------------------\n",
    "# Loop over different seeds\n",
    "# -------------------------\n",
    "for seed in seeds:\n",
    "\n",
    "    cv = KFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    dt = DecisionTreeRegressor(random_state=seed)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=dt,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "\n",
    "    # 使用 tree 的 preprocessing\n",
    "    grid.fit(X_train_tree, y_train_log)\n",
    "\n",
    "    best_dt = grid.best_estimator_\n",
    "\n",
    "    # -------------------------\n",
    "    # Print CV performance\n",
    "    # -------------------------\n",
    "    print(f\"\\nSeed {seed} | Best Params: {grid.best_params_}\")\n",
    "    print(\"Best CV RMSE:\", -grid.best_score_)\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred_log = best_dt.predict(X_test_tree)\n",
    "\n",
    "    rmse_log = mean_squared_error(y_test_log, y_pred_log) ** 0.5\n",
    "    r2_log = r2_score(y_test_log, y_pred_log)\n",
    "\n",
    "    rmse_list.append(rmse_log)\n",
    "    r2_list.append(r2_log)\n",
    "\n",
    "    print(f\"Test RMSE = {rmse_log:.4f} | Test R² = {r2_log:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n----------------- Summary ---------------\\n\")\n",
    "print(f\"Mean RMSE (log10 space): {np.mean(rmse_list):.4f}\")\n",
    "print(f\"Std RMSE (log10 space):  {np.std(rmse_list):.4f}\")\n",
    "print(f\"Mean R²  (log10 space):  {np.mean(r2_list):.4f}\")\n",
    "print(f\"Std R²   (log10 space):   {np.std(r2_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------\n",
    "# Multiple random states for stability\n",
    "# ---------------------------------------\n",
    "seeds = [0]\n",
    "\n",
    "# 保存每个 seed 的结果\n",
    "rmse_list = []\n",
    "r2_list = []\n",
    "\n",
    "# ---------------------------------------\n",
    "# Reduced + Optimized Parameter Grid\n",
    "# 因为 ZIP → LAT/LON 特征减少，不再需要非常强的正则化\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],     # 足够稳定且比 300 快\n",
    "    'max_depth': [5, 10, 20, 30],          # 降低深度，大幅提升速度\n",
    "    'min_samples_split': [2, 10],   # 控制过拟合\n",
    "    'max_features': ['sqrt', 0.3]   # sqrt 经典，0.3 更强随机性\n",
    "}\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    print(f\"\\n---------------Running seed = {seed} ---------------\")\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        random_state=seed,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    cv = KFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=rf,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # fit\n",
    "    grid.fit(X_train_tree, y_train_log)\n",
    "\n",
    "    print(\"Best Params:\", grid.best_params_)\n",
    "    print(\"Best CV RMSE:\", -grid.best_score_)\n",
    "\n",
    "    best_rf = grid.best_estimator_\n",
    "\n",
    "    # test set performance\n",
    "    y_pred_test = best_rf.predict(X_test_tree)\n",
    "\n",
    "    rmse_test = mean_squared_error(y_test_log, y_pred_test)**0.5\n",
    "    r2_test = r2_score(y_test_log, y_pred_test)\n",
    "\n",
    "    rmse_list.append(rmse_test)\n",
    "    r2_list.append(r2_test)\n",
    "\n",
    "    print(\"Test RMSE (log10):\", rmse_test)\n",
    "    print(\"Test R² (log10):\", r2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc76f0ad",
   "metadata": {},
   "source": [
    "\n",
    "---------------RF Running seed = 0 ---------------\n",
    "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
    "Best Params: {'max_depth': 30, 'max_features': 0.3, 'min_samples_split': 2, 'n_estimators': 300}\n",
    "Best CV RMSE: 0.3138019952936816\n",
    "Test RMSE (log10): 0.3241411412667523\n",
    "Test R² (log10): 0.6141635229079763\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1b5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------Running seed = 42 ---------------\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------\n",
    "# Multiple random states for stability\n",
    "# ---------------------------------------\n",
    "seeds = [42]\n",
    "\n",
    "# 保存每个 seed 的结果\n",
    "rmse_list = []\n",
    "r2_list = []\n",
    "\n",
    "# ---------------------------------------\n",
    "# Reduced + Optimized Parameter Grid\n",
    "# 因为 ZIP → LAT/LON 特征减少，不再需要非常强的正则化\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],     # 足够稳定且比 300 快\n",
    "    'max_depth': [5, 10, 20, 30],          # 降低深度，大幅提升速度\n",
    "    'min_samples_split': [2, 10],   # 控制过拟合\n",
    "    'max_features': ['sqrt', 0.3]   # sqrt 经典，0.3 更强随机性\n",
    "}\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    print(f\"\\n---------------Running seed = {seed} ---------------\")\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        random_state=seed,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    cv = KFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=rf,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # fit\n",
    "    grid.fit(X_train_tree, y_train_log)\n",
    "\n",
    "    print(\"Best Params:\", grid.best_params_)\n",
    "    print(\"Best CV RMSE:\", -grid.best_score_)\n",
    "\n",
    "    best_rf = grid.best_estimator_\n",
    "\n",
    "    # test set performance\n",
    "    y_pred_test = best_rf.predict(X_test_tree)\n",
    "\n",
    "    rmse_test = mean_squared_error(y_test_log, y_pred_test)**0.5\n",
    "    r2_test = r2_score(y_test_log, y_pred_test)\n",
    "\n",
    "    rmse_list.append(rmse_test)\n",
    "    r2_list.append(r2_test)\n",
    "\n",
    "    print(\"Test RMSE (log10):\", rmse_test)\n",
    "    print(\"Test R² (log10):\", r2_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb157490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------\n",
    "# Multiple random states for stability\n",
    "# ---------------------------------------\n",
    "# 保存每个 seed 的结果\n",
    "rmse_list = []\n",
    "r2_list = []\n",
    "seeds = [141]\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# Reduced + Optimized Parameter Grid\n",
    "# 因为 ZIP → LAT/LON 特征减少，不再需要非常强的正则化\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],     # 足够稳定且比 300 快\n",
    "    'max_depth': [5, 10, 20, 30],          # 降低深度，大幅提升速度\n",
    "    'min_samples_split': [2, 10],   # 控制过拟合\n",
    "    'max_features': ['sqrt', 0.3]   # sqrt 经典，0.3 更强随机性\n",
    "}\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    print(f\"\\n---------------Running seed = {seed} ---------------\")\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        random_state=seed,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    cv = KFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=rf,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # fit\n",
    "    grid.fit(X_train_tree, y_train_log)\n",
    "\n",
    "    print(\"Best Params:\", grid.best_params_)\n",
    "    print(\"Best CV RMSE:\", -grid.best_score_)\n",
    "\n",
    "    best_rf = grid.best_estimator_\n",
    "\n",
    "    # test set performance\n",
    "    y_pred_test = best_rf.predict(X_test_tree)\n",
    "\n",
    "    rmse_test = mean_squared_error(y_test_log, y_pred_test)**0.5\n",
    "    r2_test = r2_score(y_test_log, y_pred_test)\n",
    "\n",
    "    rmse_list.append(rmse_test)\n",
    "    r2_list.append(r2_test)\n",
    "\n",
    "    print(\"Test RMSE (log10):\", rmse_test)\n",
    "    print(\"Test R² (log10):\", r2_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Summary\n",
    "# ---------------------------------------\n",
    "print(\"\\n------------- SUMMARY ---------------\\n\")\n",
    "print(f\"Mean Test RMSE (log10): {np.mean(rmse_list):.4f}\")\n",
    "print(f\"Std Test RMSE  (log10): {np.std(rmse_list):.4f}\")\n",
    "print(f\"Mean Test R²   (log10): {np.mean(r2_list):.4f}\")\n",
    "print(f\"Std Test R²    (log10): {np.std(r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# Parameter grid for tuning\n",
    "# -------------------------\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.03, 0.08],\n",
    "    \"subsample\": [0.6, 0.8],\n",
    "    'max_depth': [5, 10, 20, 30],          # 降低深度，大幅提升速度\n",
    "    \"min_child_weight\": [3, 5],\n",
    "    \"colsample_bytree\": [0.8, 0.6],\n",
    "    \"n_estimators\": [10000],   # 实际不会训练到 1 万棵树，会被 early stopping 停止\n",
    "}\n",
    "\n",
    "seeds = [0, 42, 141]\n",
    "\n",
    "rmse_list = []\n",
    "r2_list = []\n",
    "\n",
    "# -------------------------\n",
    "# Loop over seeds\n",
    "# -------------------------\n",
    "for seed in seeds:\n",
    "\n",
    "    print(f\"\\n--------------- Seed {seed} ----------------\")\n",
    "\n",
    "    # 用 KFold 和其他模型保持一致\n",
    "    cv = KFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    # 基础模型\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        missing=np.nan,\n",
    "        random_state=seed,\n",
    "        n_jobs=-1,\n",
    "        early_stopping_rounds=30   # ⭐ 必须包含 early stopping\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # GridSearchCV — 超参数搜索\n",
    "    # -------------------------\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # 注意：XGBoost 的 early stopping 需要 eval_set\n",
    "    grid.fit(\n",
    "        X_train_xgb, \n",
    "        y_train_log,\n",
    "        eval_set=[(X_valid_xgb, y_valid_log_xgb)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    best_xgb = grid.best_estimator_\n",
    "\n",
    "    # -------------------------\n",
    "    # Print CV result\n",
    "    # -------------------------\n",
    "    print(\"Best Params:\", grid.best_params_)\n",
    "    print(\"Best CV RMSE:\", -grid.best_score_) \n",
    "\n",
    "    # -------------------------\n",
    "    # Test set evaluation\n",
    "    # -------------------------\n",
    "    y_pred_log = best_xgb.predict(X_test_xgb)\n",
    "\n",
    "    rmse_log = mean_squared_error(y_test_log_xgb, y_pred_log)**0.5\n",
    "    r2_log  = r2_score(y_test_log_xgb, y_pred_log)\n",
    "\n",
    "\n",
    "    rmse_list.append(rmse_log)\n",
    "    r2_list.append(r2_log)\n",
    "\n",
    "    print(f\"Test RMSE = {rmse_log:.4f} | Test R² = {r2_log:.4f}\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Summary\n",
    "# -------------------------\n",
    "print(\"\\n----------------- Summary ---------------\\n\")\n",
    "print(f\"Mean RMSE (log10 space): {np.mean(rmse_list):.4f}\")\n",
    "print(f\"Std  RMSE (log10 space): {np.std(rmse_list):.4f}\")\n",
    "print(f\"Mean R²  (log10 space):  {np.mean(r2_list):.4f}\")\n",
    "print(f\"Std  R²  (log10 space):  {np.std(r2_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a77b56b",
   "metadata": {},
   "source": [
    "--------------- XGBoost Seed 0 ----------------\n",
    "Best Params: {'colsample_bytree': 0.6, 'learning_rate': 0.03, 'max_depth': 20, 'min_child_weight': 3, 'n_estimators': 10000, 'subsample': 0.6}\n",
    "Best CV RMSE: 0.42379481680304687\n",
    "Test RMSE = 0.4502 | Test R² = 0.3072\n",
    "\n",
    "--------------- XGBoost Seed 42 ----------------\n",
    "Best Params: {'colsample_bytree': 0.6, 'learning_rate': 0.03, 'max_depth': 20, 'min_child_weight': 3, 'n_estimators': 10000, 'subsample': 0.6}\n",
    "Best CV RMSE: 0.4227139449707408\n",
    "Test RMSE = 0.4501 | Test R² = 0.3076\n",
    "\n",
    "--------------- XGBoost Seed 141 ----------------\n",
    "Best Params: {'colsample_bytree': 0.6, 'learning_rate': 0.03, 'max_depth': 20, 'min_child_weight': 3, 'n_estimators': 10000, 'subsample': 0.6}\n",
    "Best CV RMSE: 0.42453091153379674\n",
    "Test RMSE = 0.4502 | Test R² = 0.3071\n",
    "\n",
    "----------------- Summary -----------------\n",
    "Mean RMSE: 0.4502\n",
    "Std RMSE:  0.0001\n",
    "Mean R²:   0.3073\n",
    "Std R²:    0.0002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c8e274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv('../data/data.csv')\n",
    "df = df.dropna(subset=['state']) #罪过 最后要悄悄删掉\n",
    "df = df.dropna(subset=['price'])\n",
    "y = df['price']\n",
    "X = df.loc[:, df.columns != 'price']\n",
    "# Counting occurrences of each state\n",
    "state_counts = X['state'].value_counts()\n",
    "\n",
    "# Set common and rare states\n",
    "common_states = state_counts[state_counts >= 2].index\n",
    "rare_states = state_counts[state_counts < 2].index\n",
    "\n",
    "# splitting the dataset\n",
    "mask_common = X['state'].isin(common_states)\n",
    "mask_rare = X['state'].isin(rare_states)\n",
    "\n",
    "X_common, y_common = X[mask_common], y[mask_common]\n",
    "X_rare, y_rare = X[mask_rare], y[mask_rare]\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_common, y_common, train_size=0.98, stratify=X_common['state'], random_state=random_state\n",
    ")\n",
    "\n",
    "\n",
    "X_train = pd.concat([X_train, X_rare]).reset_index(drop=True)\n",
    "y_train = pd.concat([y_train, y_rare]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Reset test set index\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_train_tree = tree_preprocessor.fit_transform(X_train)\n",
    "X_test_tree = tree_preprocessor.transform(X_test)\n",
    "\n",
    "# 避免 log10(0) 错误，加一个非常小的常数（安全做法）\n",
    "y_train_log = np.log10(y_train + 1e-6)\n",
    "y_test_log = np.log10(y_test + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b01966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit RF model with best parameter\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "rf_final = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=30,\n",
    "    max_features=0.3,\n",
    "    min_samples_split=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit\n",
    "rf_final.fit(X_train_tree, y_train_log)\n",
    "\n",
    "\n",
    "# Predict\n",
    "y_pred_log = rf_final.predict(X_test_tree)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "rmse = mean_squared_error(y_test_log, y_pred_log) ** 0.5\n",
    "r2   = r2_score(y_test_log, y_pred_log)\n",
    "\n",
    "print(\"Random Forest Final Model Performance\")\n",
    "print(f\"Test RMSE (log10): {rmse:.4f}\")\n",
    "print(f\"Test R²   (log10): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91531eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 0. Options\n",
    "# -----------------------------\n",
    "sample_frac = 0.01      # 抽样比例（1%）\n",
    "show_diag = True        # 是否显示 y=x 理想参考线（不想要就改 False）\n",
    "seed = 42\n",
    "\n",
    "# -----------------------------\n",
    "# 1. 随机抽样\n",
    "# -----------------------------\n",
    "n = len(y_test_log)\n",
    "rng = np.random.default_rng(seed)\n",
    "m = max(1, int(n * sample_frac))\n",
    "idx = rng.choice(n, size=m, replace=False)\n",
    "\n",
    "# y_test_log 如果是 pandas Series，用 iloc；如果是 numpy array，也能兼容\n",
    "y_true_sample = y_test_log.iloc[idx] if hasattr(y_test_log, \"iloc\") else y_test_log[idx]\n",
    "y_pred_sample = y_pred_log[idx]\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Plot\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.scatter(\n",
    "    y_true_sample,\n",
    "    y_pred_sample,\n",
    "    alpha=0.25,\n",
    "    s=10\n",
    ")\n",
    "\n",
    "# 参考线：y = x\n",
    "if show_diag:\n",
    "    min_val = min(np.min(y_true_sample), np.min(y_pred_sample))\n",
    "    max_val = max(np.max(y_true_sample), np.max(y_pred_sample))\n",
    "    plt.plot(\n",
    "        [min_val, max_val],\n",
    "        [min_val, max_val],\n",
    "        linestyle=\"--\",\n",
    "        linewidth=1.2,\n",
    "        label=\"Ideal: y = x\"\n",
    "    )\n",
    "\n",
    "# 网格\n",
    "plt.grid(True, linestyle=\"--\", linewidth=0.6, alpha=0.6)\n",
    "\n",
    "# 轴标签 & 标题\n",
    "plt.xlabel(\"True log10(Price)\", fontsize=12)\n",
    "plt.ylabel(\"Predicted log10(Price)\", fontsize=12)\n",
    "plt.title(\"Random Forest: Predicted vs True (Test Set)\", fontsize=14)\n",
    "\n",
    "# 图例\n",
    "plt.legend(frameon=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad167a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Global Feature Importance\n",
    "# Permutation Importance (Top 10)\n",
    "# ============================\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. 取特征名（来自 tree_preprocessor）\n",
    "feature_names = tree_preprocessor.get_feature_names_out()\n",
    "\n",
    "# 2. 计算 permutation importance（在 test set 上）\n",
    "perm_result = permutation_importance(\n",
    "    rf_final,\n",
    "    X_test_tree,\n",
    "    y_test_log,\n",
    "    n_repeats=2,\n",
    "    random_state=42,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 3. 整理结果\n",
    "perm_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": perm_result.importances_mean\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "# 4. 取 Top 10\n",
    "top10_perm = perm_df.head(10)\n",
    "\n",
    "print(\"Top 10 Permutation Feature Importance:\")\n",
    "print(top10_perm)\n",
    "\n",
    "# 5. Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(\n",
    "    top10_perm[\"feature\"][::-1],\n",
    "    top10_perm[\"importance\"][::-1]\n",
    ")\n",
    "plt.xlabel(\"Permutation Importance (Increase in RMSE)\", fontsize=12)\n",
    "plt.title(\"Global Feature Importance (Permutation, Top 10)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Local Feature Importance\n",
    "# SHAP Force Plots (Selected Instances Only)\n",
    "# ============================\n",
    "\n",
    "import shap\n",
    "\n",
    "# TreeExplainer for Random Forest\n",
    "explainer = shap.TreeExplainer(rf_final)\n",
    "\n",
    "# 你指定的 test index\n",
    "requested_indices = [100, 1000, 10000]\n",
    "n_test = X_test_tree.shape[0]\n",
    "selected_indices = [i for i in requested_indices if i < n_test]\n",
    "\n",
    "print(\"Using test indices:\", selected_indices)\n",
    "print(\"Test set size:\", n_test)\n",
    "\n",
    "# 只取需要解释的样本\n",
    "X_shap = X_test_tree[selected_indices]\n",
    "\n",
    "# ⭐ 只对这几个样本计算 SHAP\n",
    "shap_values = explainer.shap_values(X_shap)\n",
    "\n",
    "# 逐个画 force plot\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    print(f\"\\nSHAP force plot for test sample index = {idx}\")\n",
    "\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value,\n",
    "        shap_values[i],\n",
    "        X_shap[i],\n",
    "        feature_names=feature_names,\n",
    "        matplotlib=True   # 静态图，适合 PPT\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
