{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a95aa31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2226382, 12)\n",
      "(2224833, 11)\n",
      "Train size: 2180336\n",
      "Validation size: 22248\n",
      "Test size: 22249\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv('../data/data.csv')\n",
    "print(df.shape)\n",
    "df = df.dropna(subset=['state']) #罪过 最后要悄悄删掉\n",
    "df = df.dropna(subset=['price'])\n",
    "df=df.drop(columns=[\"zip_code\"])\n",
    "print(df.shape)\n",
    "y = df['price']\n",
    "X = df.loc[:, df.columns != 'price']\n",
    "# Counting occurrences of each state\n",
    "state_counts = X['state'].value_counts()\n",
    "\n",
    "# Set common and rare states\n",
    "common_states = state_counts[state_counts >= 2].index\n",
    "rare_states = state_counts[state_counts < 2].index\n",
    "\n",
    "# splitting the dataset\n",
    "mask_common = X['state'].isin(common_states)\n",
    "mask_rare = X['state'].isin(rare_states)\n",
    "\n",
    "X_common, y_common = X[mask_common], y[mask_common]\n",
    "X_rare, y_rare = X[mask_rare], y[mask_rare]\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_other, y_train, y_other = train_test_split(\n",
    "    X_common, y_common, train_size=0.98, stratify=X_common['state'], random_state=random_state\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_other, y_other, train_size=0.5, random_state=random_state\n",
    ")\n",
    "\n",
    "X_train = pd.concat([X_train, X_rare])\n",
    "y_train = pd.concat([y_train, y_rare])\n",
    "\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Validation size:\", len(X_val))\n",
    "print(\"Test size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "736223c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Column Data_Type  Num_NA  NA_Rate\n",
      "0   prev_sold_date    object  733248    0.330\n",
      "1       house_size   float64  567872    0.255\n",
      "2             bath   float64  510984    0.230\n",
      "3              bed   float64  480859    0.216\n",
      "4         acre_lot   float64  325134    0.146\n",
      "5           street   float64   10864    0.005\n",
      "6      brokered_by   float64    4533    0.002\n",
      "7             city    object    1404    0.001\n",
      "8         zip_code   float64     296    0.000\n",
      "9           status    object       0    0.000\n",
      "10           price   float64       0    0.000\n",
      "11           state    object       0    0.000\n"
     ]
    }
   ],
   "source": [
    "# Check NA for each column\n",
    "\n",
    "cols = ['brokered_by', 'status', 'price', 'bed', 'bath', \n",
    "        'acre_lot', 'street', 'city', 'state', 'zip_code', \n",
    "        'house_size', 'prev_sold_date']\n",
    "\n",
    "na_summary = pd.DataFrame({\n",
    "    'Column': cols,\n",
    "    'Data_Type': [df[c].dtype for c in cols],\n",
    "    'Num_NA': [df[c].isna().sum() for c in cols],\n",
    "    'NA_Rate': [round(df[c].isna().mean(), 3) for c in cols]\n",
    "})\n",
    "\n",
    "na_summary = na_summary.sort_values('Num_NA', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(na_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef69d2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Column Data_Type  Min           Max         Q1         Q3  Lower_Bound  \\\n",
      "0    acre_lot   float64  0.0  1.000000e+05       0.15       0.98         -1.1   \n",
      "1       price   float64  0.0  2.147484e+09  165000.00  550000.00    -412500.0   \n",
      "2         bed   float64  1.0  4.730000e+02       3.00       4.00          1.5   \n",
      "3        bath   float64  1.0  8.300000e+02       2.00       3.00          0.5   \n",
      "4  house_size   float64  4.0  1.040400e+09    1300.00    2413.00       -369.5   \n",
      "\n",
      "   Upper_Bound  Num_Outliers  Outlier_Rate  \n",
      "0         2.22        292018         0.131  \n",
      "1   1127500.00        171600         0.077  \n",
      "2         5.50        118888         0.053  \n",
      "3         4.50         79063         0.036  \n",
      "4      4082.50         77831         0.035  \n"
     ]
    }
   ],
   "source": [
    "# Check outliers for numeric columns using IQR method\n",
    "\n",
    "def detect_outliers_iqr(df, columns):\n",
    "    outlier_summary = []\n",
    "    for col in columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):  # Check if the column is numeric\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - 1.5 * IQR\n",
    "            upper = Q3 + 1.5 * IQR\n",
    "            outliers = ((df[col] < lower) | (df[col] > upper)).sum()\n",
    "            outlier_ratio = round(outliers / len(df), 3)\n",
    "            col_min = df[col].min()\n",
    "            col_max = df[col].max()\n",
    "            \n",
    "            outlier_summary.append([\n",
    "                col,\n",
    "                df[col].dtype,\n",
    "                round(df[col].min(), 2),\n",
    "                round(df[col].max(), 2),\n",
    "                round(Q1, 2),\n",
    "                round(Q3, 2),\n",
    "                round(lower, 2),\n",
    "                round(upper, 2),\n",
    "                outliers,\n",
    "                outlier_ratio\n",
    "            ])\n",
    "    \n",
    "    outlier_table = pd.DataFrame(outlier_summary, columns=[\n",
    "        'Column', 'Data_Type', 'Min', 'Max', 'Q1', 'Q3', \n",
    "        'Lower_Bound', 'Upper_Bound', 'Num_Outliers', 'Outlier_Rate'\n",
    "    ])\n",
    "    \n",
    "    return outlier_table.sort_values('Outlier_Rate', ascending=False).reset_index(drop=True)\n",
    "\n",
    "numeric_cols = ['price', 'bed', 'bath', 'acre_lot', 'house_size']\n",
    "outlier_table = detect_outliers_iqr(df, numeric_cols)\n",
    "print(outlier_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Pipeline\n",
    "\n",
    "# preprocess with pipeline and columntransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "# collect the various features\n",
    "cat_ftrs = ['status','city','state']\n",
    "num_ftrs = ['bed','bath','acre_lot','house_size']\n",
    "zip_ftr = 'zip_code'\n",
    "broker_ftr = 'brokered_by'\n",
    "street_ftr = 'street'\n",
    "sold_ftr = 'prev_sold_date'\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "class BinaryTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # NA → 0；非 NA → 1\n",
    "        return np.where(pd.isna(X), 0, 1).reshape(-1,1)\n",
    "\n",
    "class ZipCodeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.iloc[:, 0]\n",
    "        zip_str = X.astype(str)\n",
    "        zip_str = zip_str.str.split('.').str[0]\n",
    "        # 去掉非数字字符（例如 \"#####\", \"nan\", etc.）\n",
    "        zip_str = zip_str.apply(lambda s: ''.join(ch for ch in s if ch.isdigit()))\n",
    "        # 空字符串 → 视为缺失\n",
    "        zip_str = zip_str.replace('', np.nan)\n",
    "        # 缺失 ZIP → 用 \"00000\" 填充\n",
    "        zip_str = zip_str.fillna(\"00000\")\n",
    "        # ⭐ 最重要：统一补足为 5 位 ZIP（不足前补零）\n",
    "        zip_str = zip_str.str.zfill(5)\n",
    "        return zip_str.values.reshape(-1, 1)\n",
    "\n",
    "    \n",
    "class PrevSoldDateTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.iloc[:, 0]     # 只有一列\n",
    "        else:\n",
    "            X = pd.Series(X)\n",
    "\n",
    "        dates = pd.to_datetime(X, errors='coerce')\n",
    "        years = (datetime.now() - dates).dt.days / 365\n",
    "        years = years.fillna(-1)\n",
    "\n",
    "        return years.values.reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "# one-hot encoder and imputer\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=True,handle_unknown='ignore'))])\n",
    "# standard scaler and imputer\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=10, random_state=42)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "tree_numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=10, random_state=42))])\n",
    "\n",
    "broker_pipe = Pipeline(steps=[\n",
    "    ('binary', BinaryTransformer())\n",
    "])\n",
    "street_pipe = Pipeline(steps=[\n",
    "    ('binary', BinaryTransformer())\n",
    "])\n",
    "zip_pipe = Pipeline(steps=[\n",
    "    ('zip_transform', ZipCodeTransformer()),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "])\n",
    "sold_pipe = Pipeline(steps=[\n",
    "    ('sold_transform', PrevSoldDateTransformer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('broker', broker_pipe, broker_ftr),\n",
    "        ('street', street_pipe, street_ftr),\n",
    "        ('zip', zip_pipe, zip_ftr),\n",
    "        ('sold', sold_pipe, sold_ftr)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "\n",
    "tree_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', tree_numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('broker', broker_pipe, broker_ftr),\n",
    "        ('street', street_pipe, street_ftr),\n",
    "        ('zip', zip_pipe, zip_ftr),\n",
    "        ('sold', sold_pipe, sold_ftr)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "\n",
    "xgb_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('broker', broker_pipe, broker_ftr),\n",
    "        ('street', street_pipe, street_ftr),\n",
    "        ('zip', zip_pipe, zip_ftr),\n",
    "        ('sold', sold_pipe, sold_ftr)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f1a4771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2224833, 12)\n"
     ]
    }
   ],
   "source": [
    "# save small dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv('../data/data.csv')\n",
    "df = df.dropna(subset=['state']) #罪过 最后要悄悄删掉\n",
    "df = df.dropna(subset=['price'])\n",
    "# df=df.drop(columns=[\"zip_code\"])\n",
    "print(df.shape)\n",
    "X = df.loc[:, df.columns != 'price']\n",
    "# Counting occurrences of each state\n",
    "state_counts = X['state'].value_counts()\n",
    "# Set common and rare states\n",
    "common_states = state_counts[state_counts >= 2].index\n",
    "rare_states = state_counts[state_counts < 2].index\n",
    "# splitting the dataset\n",
    "mask_common = X['state'].isin(common_states)\n",
    "mask_rare = X['state'].isin(rare_states)\n",
    "X_common, y_common = X[mask_common], y[mask_common]\n",
    "X_rare, y_rare = X[mask_rare], y[mask_rare]\n",
    "\n",
    "\n",
    "X_small_c, _, y_small_c, _ = train_test_split(\n",
    "    X_common,\n",
    "    y_common,\n",
    "    test_size=0.99,                     # keep 1%\n",
    "    stratify=X_common['state'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_small = pd.concat([X_small_c, X_rare], axis=0).reset_index(drop=True)\n",
    "y_small = pd.concat([y_small_c, y_rare], axis=0).reset_index(drop=True)\n",
    "\n",
    "X_small.to_csv(\"../data/X_small.csv\", index=False)\n",
    "y_small.to_csv(\"../data/y_small.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
