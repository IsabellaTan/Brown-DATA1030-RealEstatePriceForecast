{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95aa31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv('../data/data.csv')\n",
    "y = df['price'] \n",
    "X = df.loc[:, df.columns != 'price']\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# first split to separate out the training set\n",
    "X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.98,random_state = random_state)\n",
    "# X_train, y_train → 98% X_other, y_other → 2%\n",
    "# second split to separate out the validation and test sets \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,\\\n",
    "                    train_size = 0.5,random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "736223c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Column Data_Type  Num_NA  NA_Rate\n",
      "0   prev_sold_date    object  734297    0.330\n",
      "1       house_size   float64  568484    0.255\n",
      "2             bath   float64  511771    0.230\n",
      "3              bed   float64  481317    0.216\n",
      "4         acre_lot   float64  325589    0.146\n",
      "5           street   float64   10866    0.005\n",
      "6      brokered_by   float64    4533    0.002\n",
      "7            price   float64    1541    0.001\n",
      "8             city    object    1407    0.001\n",
      "9         zip_code   float64     299    0.000\n",
      "10           state    object       8    0.000\n",
      "11          status    object       0    0.000\n"
     ]
    }
   ],
   "source": [
    "# Check NA for each column\n",
    "\n",
    "cols = ['brokered_by', 'status', 'price', 'bed', 'bath', \n",
    "        'acre_lot', 'street', 'city', 'state', 'zip_code', \n",
    "        'house_size', 'prev_sold_date']\n",
    "\n",
    "na_summary = pd.DataFrame({\n",
    "    'Column': cols,\n",
    "    'Data_Type': [df[c].dtype for c in cols],\n",
    "    'Num_NA': [df[c].isna().sum() for c in cols],\n",
    "    'NA_Rate': [round(df[c].isna().mean(), 3) for c in cols]\n",
    "})\n",
    "\n",
    "na_summary = na_summary.sort_values('Num_NA', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(na_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69d2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Column Data_Type  Min           Max         Q1         Q3  Lower_Bound  \\\n",
      "0    acre_lot   float64  0.0  1.000000e+05       0.15       0.98         -1.1   \n",
      "1       price   float64  0.0  2.147484e+09  165000.00  550000.00    -412500.0   \n",
      "2         bed   float64  1.0  4.730000e+02       3.00       4.00          1.5   \n",
      "3        bath   float64  1.0  8.300000e+02       2.00       3.00          0.5   \n",
      "4  house_size   float64  4.0  1.040400e+09    1300.00    2413.00       -369.5   \n",
      "\n",
      "   Upper_Bound  Num_Outliers  Outlier_Rate  \n",
      "0         2.22        292418         0.131  \n",
      "1   1127500.00        171600         0.077  \n",
      "2         5.50        118920         0.053  \n",
      "3         4.50         79075         0.036  \n",
      "4      4082.50         77850         0.035  \n"
     ]
    }
   ],
   "source": [
    "# Check outliers for numeric columns using IQR method\n",
    "\n",
    "def detect_outliers_iqr(df, columns):\n",
    "    outlier_summary = []\n",
    "    for col in columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):  # Check if the column is numeric\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - 1.5 * IQR\n",
    "            upper = Q3 + 1.5 * IQR\n",
    "            outliers = ((df[col] < lower) | (df[col] > upper)).sum()\n",
    "            outlier_ratio = round(outliers / len(df), 3)\n",
    "            col_min = df[col].min()\n",
    "            col_max = df[col].max()\n",
    "            \n",
    "            outlier_summary.append([\n",
    "                col,\n",
    "                df[col].dtype,\n",
    "                round(df[col].min(), 2),\n",
    "                round(df[col].max(), 2),\n",
    "                round(Q1, 2),\n",
    "                round(Q3, 2),\n",
    "                round(lower, 2),\n",
    "                round(upper, 2),\n",
    "                outliers,\n",
    "                outlier_ratio\n",
    "            ])\n",
    "    \n",
    "    outlier_table = pd.DataFrame(outlier_summary, columns=[\n",
    "        'Column', 'Data_Type', 'Min', 'Max', 'Q1', 'Q3', \n",
    "        'Lower_Bound', 'Upper_Bound', 'Num_Outliers', 'Outlier_Rate'\n",
    "    ])\n",
    "    \n",
    "    return outlier_table.sort_values('Outlier_Rate', ascending=False).reset_index(drop=True)\n",
    "\n",
    "numeric_cols = ['price', 'bed', 'bath', 'acre_lot', 'house_size']\n",
    "outlier_table = detect_outliers_iqr(df, numeric_cols)\n",
    "print(outlier_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "963d4063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories: [array(['100 89 Lower Shepard Creek Road', '139th Ave Unit Peck',\n",
      "       '15th Ave Milton', ..., 'Zuni', 'Zwingle', 'Zwolle'],\n",
      "      shape=(20045,), dtype=object), array(['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California',\n",
      "       'Colorado', 'Connecticut', 'Delaware', 'District of Columbia',\n",
      "       'Florida', 'Georgia', 'Guam', 'Hawaii', 'Idaho', 'Illinois',\n",
      "       'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine',\n",
      "       'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
      "       'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
      "       'New Brunswick', 'New Hampshire', 'New Jersey', 'New Mexico',\n",
      "       'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma',\n",
      "       'Oregon', 'Pennsylvania', 'Puerto Rico', 'Rhode Island',\n",
      "       'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Unknown',\n",
      "       'Utah', 'Vermont', 'Virgin Islands', 'Virginia', 'Washington',\n",
      "       'West Virginia', 'Wisconsin', 'Wyoming'], dtype=object), array(['for_sale', 'ready_to_build', 'sold'], dtype=object)]\n",
      "feature names: ['city_100 89 Lower Shepard Creek Road' 'city_139th Ave Unit Peck'\n",
      " 'city_15th Ave Milton' ... 'status_for_sale' 'status_ready_to_build'\n",
      " 'status_sold']\n",
      "X_train transformed\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 6545562 stored elements and shape (2181854, 20104)>\n",
      "  Coords\tValues\n",
      "  (0, 6190)\t1.0\n",
      "  (0, 20054)\t1.0\n",
      "  (0, 20101)\t1.0\n",
      "  (1, 9501)\t1.0\n",
      "  (1, 20059)\t1.0\n",
      "  (1, 20101)\t1.0\n",
      "  (2, 14098)\t1.0\n",
      "  (2, 20080)\t1.0\n",
      "  (2, 20101)\t1.0\n",
      "  (3, 3131)\t1.0\n",
      "  (3, 20085)\t1.0\n",
      "  (3, 20103)\t1.0\n",
      "  (4, 7784)\t1.0\n",
      "  (4, 20090)\t1.0\n",
      "  (4, 20101)\t1.0\n",
      "  (5, 5891)\t1.0\n",
      "  (5, 20068)\t1.0\n",
      "  (5, 20101)\t1.0\n",
      "  (6, 9821)\t1.0\n",
      "  (6, 20054)\t1.0\n",
      "  (6, 20103)\t1.0\n",
      "  (7, 7218)\t1.0\n",
      "  (7, 20082)\t1.0\n",
      "  (7, 20101)\t1.0\n",
      "  (8, 6436)\t1.0\n",
      "  :\t:\n",
      "  (2181845, 20101)\t1.0\n",
      "  (2181846, 5829)\t1.0\n",
      "  (2181846, 20078)\t1.0\n",
      "  (2181846, 20101)\t1.0\n",
      "  (2181847, 16648)\t1.0\n",
      "  (2181847, 20091)\t1.0\n",
      "  (2181847, 20101)\t1.0\n",
      "  (2181848, 12081)\t1.0\n",
      "  (2181848, 20058)\t1.0\n",
      "  (2181848, 20103)\t1.0\n",
      "  (2181849, 877)\t1.0\n",
      "  (2181849, 20066)\t1.0\n",
      "  (2181849, 20103)\t1.0\n",
      "  (2181850, 13875)\t1.0\n",
      "  (2181850, 20060)\t1.0\n",
      "  (2181850, 20101)\t1.0\n",
      "  (2181851, 12414)\t1.0\n",
      "  (2181851, 20079)\t1.0\n",
      "  (2181851, 20101)\t1.0\n",
      "  (2181852, 15263)\t1.0\n",
      "  (2181852, 20054)\t1.0\n",
      "  (2181852, 20103)\t1.0\n",
      "  (2181853, 8916)\t1.0\n",
      "  (2181853, 20097)\t1.0\n",
      "  (2181853, 20103)\t1.0\n",
      "X_test transformed\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 66753 stored elements and shape (22264, 20104)>\n",
      "  Coords\tValues\n",
      "  (0, 19267)\t1.0\n",
      "  (0, 20077)\t1.0\n",
      "  (0, 20101)\t1.0\n",
      "  (1, 4493)\t1.0\n",
      "  (1, 20050)\t1.0\n",
      "  (1, 20101)\t1.0\n",
      "  (2, 17292)\t1.0\n",
      "  (2, 20096)\t1.0\n",
      "  (2, 20102)\t1.0\n",
      "  (3, 3017)\t1.0\n",
      "  (3, 20096)\t1.0\n",
      "  (3, 20103)\t1.0\n",
      "  (4, 4349)\t1.0\n",
      "  (4, 20099)\t1.0\n",
      "  (4, 20101)\t1.0\n",
      "  (5, 11609)\t1.0\n",
      "  (5, 20064)\t1.0\n",
      "  (5, 20101)\t1.0\n",
      "  (6, 19997)\t1.0\n",
      "  (6, 20083)\t1.0\n",
      "  (6, 20103)\t1.0\n",
      "  (7, 19793)\t1.0\n",
      "  (7, 20079)\t1.0\n",
      "  (7, 20101)\t1.0\n",
      "  (8, 19910)\t1.0\n",
      "  :\t:\n",
      "  (22255, 20103)\t1.0\n",
      "  (22256, 3159)\t1.0\n",
      "  (22256, 20059)\t1.0\n",
      "  (22256, 20101)\t1.0\n",
      "  (22257, 11759)\t1.0\n",
      "  (22257, 20077)\t1.0\n",
      "  (22257, 20101)\t1.0\n",
      "  (22258, 2980)\t1.0\n",
      "  (22258, 20082)\t1.0\n",
      "  (22258, 20101)\t1.0\n",
      "  (22259, 14375)\t1.0\n",
      "  (22259, 20054)\t1.0\n",
      "  (22259, 20101)\t1.0\n",
      "  (22260, 3069)\t1.0\n",
      "  (22260, 20090)\t1.0\n",
      "  (22260, 20101)\t1.0\n",
      "  (22261, 17160)\t1.0\n",
      "  (22261, 20055)\t1.0\n",
      "  (22261, 20103)\t1.0\n",
      "  (22262, 884)\t1.0\n",
      "  (22262, 20084)\t1.0\n",
      "  (22262, 20101)\t1.0\n",
      "  (22263, 15421)\t1.0\n",
      "  (22263, 20054)\t1.0\n",
      "  (22263, 20101)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Categorical feature encoding with OneHotEncoder\n",
    "X_train['city'] = X_train['city'].fillna('Unknown')\n",
    "X_train['state'] = X_train['state'].fillna('Unknown')\n",
    "\n",
    "enc = OneHotEncoder(sparse_output=True, handle_unknown='ignore') # use sparse matrix because there are too many categories\n",
    "\n",
    "ftrs = ['city', 'state','status']\n",
    "\n",
    "enc.fit(X_train[['city', 'state','status']])\n",
    "\n",
    "\n",
    "print('categories:',enc.categories_)\n",
    "print('feature names:',enc.get_feature_names_out(ftrs))\n",
    "\n",
    "# transform X_train\n",
    "X_train_ohe = enc.transform(X_train[['city', 'state','status']])\n",
    "#print(X_train_ohe)\n",
    "# do all of this in one step\n",
    "X_train_ohe = enc.fit_transform(X_train[['city', 'state','status']])\n",
    "print('X_train transformed')\n",
    "print(X_train_ohe)\n",
    "\n",
    "# transform X_test\n",
    "X_test_ohe = enc.transform(X_test[['city', 'state','status']])\n",
    "print('X_test transformed')\n",
    "print(X_test_ohe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical feature 后续可能需要继续处理\n",
    "\n",
    "# Handle missing values\n",
    "\n",
    "# brokered_by\n",
    "# NA means no broker → fill with \"Unknown Broker\"\n",
    "# 我感觉直接分成有没有agent更好，变成dummy\n",
    "df['brokered_by'] = df['brokered_by'].fillna('Unknown Broker')\n",
    "\n",
    "# zip_code\n",
    "# NA means unknown zip → fill with \"Unknown Zip\"\n",
    "# 需要救援\n",
    "df['zip_code'] = df['zip_code'].fillna('Unknown Zip')\n",
    "\n",
    "# street\n",
    "# NA means unknown street → fill with \"Unknown Street\"\n",
    "# 我建议drop,因为有很多地理信息可以定位到房子的位置了\n",
    "df['street'] = df['street'].fillna('Unknown Street')\n",
    "\n",
    "# prev_sold_date\n",
    "# NA means haven't sold → fill with \"Never Sold\"\n",
    "# 需要救援\n",
    "df['prev_sold_date'] = df['prev_sold_date'].fillna('Never Sold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b821f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.17577097 -0.30036533         nan -0.00164542]\n",
      " [        nan         nan -0.01917359         nan]\n",
      " [        nan         nan -0.01834116         nan]\n",
      " ...\n",
      " [-1.45073138 -0.90534897         nan -0.00217827]\n",
      " [-0.81325117 -0.30036533 -0.01979461 -0.0016393 ]\n",
      " [-0.17577097 -0.30036533 -0.01974176 -0.00160255]]\n",
      "[[-1.75770971e-01 -3.00365330e-01 -8.03485668e-03             nan]\n",
      " [-1.75770971e-01 -3.00365330e-01 -1.97946116e-02 -1.13829816e-03]\n",
      " [ 4.61709232e-01             nan             nan -2.30620848e-04]\n",
      " ...\n",
      " [-1.75770971e-01  3.04618308e-01 -1.86054229e-02 -6.56898451e-04]\n",
      " [ 1.09918943e+00  9.09601946e-01             nan -5.85852184e-04]\n",
      " [            nan             nan -1.96492664e-02             nan]]\n"
     ]
    }
   ],
   "source": [
    "# continuous feature scaling with StandardScaler\n",
    "\n",
    "# 处理outliers需要进一步的去问，因为不知道这些值是不是错误数据\n",
    "\n",
    "X_train_countinuous = X_train[['bed', 'bath', 'acre_lot', 'house_size']]\n",
    "X_test_countinuous = X_test[['bed', 'bath', 'acre_lot', 'house_size']]\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit_transform(X_train_countinuous))\n",
    "print(scaler.transform(X_test_countinuous))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
