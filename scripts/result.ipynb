{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93aeaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv('../data/data.csv')\n",
    "df = df.dropna(subset=['state']) #罪过 最后要悄悄删掉\n",
    "df = df.dropna(subset=['price'])\n",
    "y = df['price']\n",
    "X = df.loc[:, df.columns != 'price']\n",
    "# Counting occurrences of each state\n",
    "state_counts = X['state'].value_counts()\n",
    "\n",
    "# Set common and rare states\n",
    "common_states = state_counts[state_counts >= 2].index\n",
    "rare_states = state_counts[state_counts < 2].index\n",
    "\n",
    "# splitting the dataset\n",
    "mask_common = X['state'].isin(common_states)\n",
    "mask_rare = X['state'].isin(rare_states)\n",
    "\n",
    "X_common, y_common = X[mask_common], y[mask_common]\n",
    "X_rare, y_rare = X[mask_rare], y[mask_rare]\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_common, y_common, train_size=0.98, stratify=X_common['state'], random_state=random_state\n",
    ")\n",
    "\n",
    "\n",
    "X_train = pd.concat([X_train, X_rare]).reset_index(drop=True)\n",
    "y_train = pd.concat([y_train, y_rare]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Reset test set index\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7005654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Pipeline\n",
    "\n",
    "# preprocess with pipeline and columntransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# collect the various features\n",
    "cat_ftrs = ['status','city','state']\n",
    "num_ftrs = ['bed','bath','acre_lot','house_size']\n",
    "zip_ftr = 'zip_code'\n",
    "broker_ftr = 'brokered_by'\n",
    "street_ftr = 'street'\n",
    "sold_ftr = 'prev_sold_date'\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "class BinaryTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # NA → 0；非 NA → 1\n",
    "        return np.where(pd.isna(X), 0, 1).reshape(-1,1)\n",
    "\n",
    "class ZipCodeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.iloc[:, 0]\n",
    "        zip_str = X.astype(str)\n",
    "        zip_str = zip_str.str.split('.').str[0]\n",
    "        # 去掉非数字字符（例如 \"#####\", \"nan\", etc.）\n",
    "        zip_str = zip_str.apply(lambda s: ''.join(ch for ch in s if ch.isdigit()))\n",
    "        # 空字符串 → 视为缺失\n",
    "        zip_str = zip_str.replace('', np.nan)\n",
    "        # 缺失 ZIP → 用 \"00000\" 填充\n",
    "        zip_str = zip_str.fillna(\"00000\")\n",
    "        # ⭐ 最重要：统一补足为 5 位 ZIP（不足前补零）\n",
    "        zip_str = zip_str.str.zfill(5)\n",
    "        return zip_str.values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "class ZipLatLonTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, zip_lookup_path):\n",
    "        self.zip_lookup_path = zip_lookup_path\n",
    "    def fit(self, X, y=None):\n",
    "        # 读取 ZIP → LAT, LON 映射表\n",
    "        df = pd.read_csv(self.zip_lookup_path)\n",
    "        # 标准化 ZIP：补齐 5 位（string）\n",
    "        df['zip'] = df['zip'].astype(str).str.zfill(5)\n",
    "        # 保存映射表\n",
    "        self.lookup = df.set_index('zip')[['lat', 'lon']]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # 如果 X 是 DataFrame，取第一列\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.iloc[:, 0]\n",
    "        # 转字符串\n",
    "        zip_str = X.astype(str).str.split('.').str[0]\n",
    "        # 去掉非数字\n",
    "        zip_str = zip_str.apply(lambda s: ''.join(ch for ch in s if ch.isdigit()))\n",
    "        # 空字符串填 \"00000\"\n",
    "        zip_str = zip_str.replace('', np.nan).fillna(\"00000\")\n",
    "        # 全部补齐为 5 位\n",
    "        zip_str = zip_str.str.zfill(5)\n",
    "        # 根据 ZIP 查 lat/lon\n",
    "        lat = zip_str.map(self.lookup['lat'])\n",
    "        lon = zip_str.map(self.lookup['lon'])\n",
    "        # 返回两列 LAT, LON\n",
    "        out = np.column_stack([lat.values, lon.values])\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class PrevSoldDateTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.iloc[:, 0]     # 只有一列\n",
    "        else:\n",
    "            X = pd.Series(X)\n",
    "\n",
    "        dates = pd.to_datetime(X, errors='coerce')\n",
    "        years = (datetime.now() - dates).dt.days / 365\n",
    "        years = years.fillna(-1)\n",
    "\n",
    "        return years.values.reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "# one-hot encoder and imputer\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=True,handle_unknown='ignore'))])\n",
    "# standard scaler and imputer\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=10, random_state=42)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "tree_numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=10, random_state=42))])\n",
    "\n",
    "broker_pipe = Pipeline(steps=[\n",
    "    ('binary', BinaryTransformer())\n",
    "])\n",
    "street_pipe = Pipeline(steps=[\n",
    "    ('binary', BinaryTransformer())\n",
    "])\n",
    "zip_pipe = Pipeline(steps=[\n",
    "    ('zip_transform', ZipCodeTransformer()),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "])\n",
    "\n",
    "zip_latlon_pipe = Pipeline([\n",
    "    ('zip_to_latlon', ZipLatLonTransformer(\"../data/zip_lat_lon.csv\")),  \n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "sold_pipe = Pipeline(steps=[\n",
    "    ('sold_transform', PrevSoldDateTransformer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "tree_sold_pipe = Pipeline(steps=[\n",
    "    ('sold_transform', PrevSoldDateTransformer())\n",
    "])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('broker', broker_pipe, broker_ftr),\n",
    "        ('street', street_pipe, street_ftr),\n",
    "        ('zip', zip_pipe, zip_ftr),\n",
    "        ('sold', sold_pipe, sold_ftr)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "\n",
    "tree_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', tree_numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('broker', broker_pipe, broker_ftr),\n",
    "        ('street', street_pipe, street_ftr),\n",
    "        ('zip', zip_latlon_pipe, zip_ftr),\n",
    "        ('sold', tree_sold_pipe, sold_ftr)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "\n",
    "xgb_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('broker', broker_pipe, broker_ftr),\n",
    "        ('street', street_pipe, street_ftr),\n",
    "        ('zip', zip_latlon_pipe, zip_ftr),\n",
    "        ('sold', tree_sold_pipe, sold_ftr)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "X_train_tree = tree_preprocessor.fit_transform(X_train)\n",
    "X_test_tree = tree_preprocessor.transform(X_test)\n",
    "\n",
    "# 避免 log10(0) 错误，加一个非常小的常数（安全做法）\n",
    "y_train_log = np.log10(y_train + 1e-6)\n",
    "y_test_log = np.log10(y_test + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97164349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit RF model with best parameter\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "rf_final = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=30,\n",
    "    max_features=0.3,\n",
    "    min_samples_split=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit\n",
    "rf_final.fit(X_train_tree, y_train_log)\n",
    "\n",
    "\n",
    "# Predict\n",
    "y_pred_log = rf_final.predict(X_test_tree)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "rmse = mean_squared_error(y_test_log, y_pred_log) ** 0.5\n",
    "r2   = r2_score(y_test_log, y_pred_log)\n",
    "\n",
    "print(\"Random Forest Final Model Performance\")\n",
    "print(f\"Test RMSE (log10): {rmse:.4f}\")\n",
    "print(f\"Test R²   (log10): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfec938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 0. Options\n",
    "# -----------------------------\n",
    "sample_frac = 0.01      # 抽样比例（1%）\n",
    "show_diag = True        # 是否显示 y=x 理想参考线（不想要就改 False）\n",
    "seed = 42\n",
    "\n",
    "# -----------------------------\n",
    "# 1. 随机抽样\n",
    "# -----------------------------\n",
    "n = len(y_test_log)\n",
    "rng = np.random.default_rng(seed)\n",
    "m = max(1, int(n * sample_frac))\n",
    "idx = rng.choice(n, size=m, replace=False)\n",
    "\n",
    "# y_test_log 如果是 pandas Series，用 iloc；如果是 numpy array，也能兼容\n",
    "y_true_sample = y_test_log.iloc[idx] if hasattr(y_test_log, \"iloc\") else y_test_log[idx]\n",
    "y_pred_sample = y_pred_log[idx]\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Plot\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.scatter(\n",
    "    y_true_sample,\n",
    "    y_pred_sample,\n",
    "    alpha=0.25,\n",
    "    s=10\n",
    ")\n",
    "\n",
    "# 参考线：y = x\n",
    "if show_diag:\n",
    "    min_val = min(np.min(y_true_sample), np.min(y_pred_sample))\n",
    "    max_val = max(np.max(y_true_sample), np.max(y_pred_sample))\n",
    "    plt.plot(\n",
    "        [min_val, max_val],\n",
    "        [min_val, max_val],\n",
    "        linestyle=\"--\",\n",
    "        linewidth=1.2,\n",
    "        label=\"Ideal: y = x\"\n",
    "    )\n",
    "\n",
    "# 网格\n",
    "plt.grid(True, linestyle=\"--\", linewidth=0.6, alpha=0.6)\n",
    "\n",
    "# 轴标签 & 标题\n",
    "plt.xlabel(\"True log10(Price)\", fontsize=12)\n",
    "plt.ylabel(\"Predicted log10(Price)\", fontsize=12)\n",
    "plt.title(\"Random Forest: Predicted vs True (Test Set)\", fontsize=14)\n",
    "\n",
    "# 图例\n",
    "plt.legend(frameon=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c89d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Global Feature Importance\n",
    "# Permutation Importance (Top 10)\n",
    "# ============================\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. 取特征名（来自 tree_preprocessor）\n",
    "feature_names = tree_preprocessor.get_feature_names_out()\n",
    "\n",
    "# 2. 计算 permutation importance（在 test set 上）\n",
    "perm_result = permutation_importance(\n",
    "    rf_final,\n",
    "    X_test_tree,\n",
    "    y_test_log,\n",
    "    n_repeats=2,\n",
    "    random_state=42,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 3. 整理结果\n",
    "perm_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": perm_result.importances_mean\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "# 4. 取 Top 10\n",
    "top10_perm = perm_df.head(10)\n",
    "\n",
    "print(\"Top 10 Permutation Feature Importance:\")\n",
    "print(top10_perm)\n",
    "\n",
    "# 5. Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(\n",
    "    top10_perm[\"feature\"][::-1],\n",
    "    top10_perm[\"importance\"][::-1]\n",
    ")\n",
    "plt.xlabel(\"Permutation Importance (Increase in RMSE)\", fontsize=12)\n",
    "plt.title(\"Global Feature Importance (Permutation, Top 10)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Local Feature Importance\n",
    "# SHAP Force Plots (Selected Instances Only)\n",
    "# ============================\n",
    "\n",
    "import shap\n",
    "\n",
    "# TreeExplainer for Random Forest\n",
    "explainer = shap.TreeExplainer(rf_final)\n",
    "\n",
    "# 你指定的 test index\n",
    "requested_indices = [100, 1000, 10000]\n",
    "n_test = X_test_tree.shape[0]\n",
    "selected_indices = [i for i in requested_indices if i < n_test]\n",
    "\n",
    "print(\"Using test indices:\", selected_indices)\n",
    "print(\"Test set size:\", n_test)\n",
    "\n",
    "# 只取需要解释的样本\n",
    "X_shap = X_test_tree[selected_indices]\n",
    "\n",
    "# ⭐ 只对这几个样本计算 SHAP\n",
    "shap_values = explainer.shap_values(X_shap)\n",
    "\n",
    "# 逐个画 force plot\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    print(f\"\\nSHAP force plot for test sample index = {idx}\")\n",
    "\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value,\n",
    "        shap_values[i],\n",
    "        X_shap[i],\n",
    "        feature_names=feature_names,\n",
    "        matplotlib=True   # 静态图，适合 PPT\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
